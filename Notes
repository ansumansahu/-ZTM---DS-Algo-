Big O Notation is the language we use for talking about how long an algorithm takes to run and which algorithm is better than the other when comes to scale, regardless our computers.

So, to fully understand and wrap it all up. When we talk about Big O and scalability of code, we simply mean we grow bigger and bigger with our Elements or inputs how much does the algorithm slow down, the less it slows down or the slower it slows down is the better. So instead of using DateTime() or Date() objects to calculate the time which is not reliable solution to test the efficiency of the code. We could just measure how many Operations the computer must perform. As each Operation takes different time on every computer. So, Big O allows us and concerns us with how many steps it takes in a function.
